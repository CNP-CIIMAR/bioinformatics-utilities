import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments
from Bio import Entrez
import requests
import speech_recognition as sr
from gtts import gTTS
import streamlit as st
from PIL import Image
import base64
import tempfile
import json
import datetime
import logging
from threading import Thread
from sentence_transformers import SentenceTransformer
import faiss
import datasets
import nltk
import numpy as np
import time
from nltk.tokenize import sent_tokenize
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Tuple
import warnings
from requests.adapters import HTTPAdapter, Retry

# 0. Configuração do Entrez com o e-mail para evitar erros
Entrez.email = "mattoslmp@gmail.com"
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# Definir o dispositivo explicitamente como CPU
device = torch.device('cpu')

# 1. Configuração do Streamlit
st.set_page_config(
    page_title="🐟 Little Fish BOGA CIIMAR",
    page_icon="🐟",
    layout="wide",
    initial_sidebar_state="expanded",
)

# 2. Configuração de logging
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = os.path.join(SCRIPT_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE_PATH = os.path.join(LOG_DIR, 'ai_agente.log')

logging.basicConfig(
    filename=LOG_FILE_PATH,
    filemode='a',
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# 3. Download do NLTK
@st.cache_resource
def download_nltk_punkt():
    try:
        nltk.download('punkt', quiet=True)
        logging.info("Pacote NLTK 'punkt' baixado.")
    except Exception as e:
        logging.error(f"Erro ao baixar o pacote NLTK 'punkt': {e}")
        st.error("Ocorreu um erro ao baixar os recursos necessários do NLTK.")

download_nltk_punkt()

# 4. Caminhos de Recursos
MODEL_DIR = "/mnt/disk_2TB/gpt-j-6B"  # Diretório do modelo
BACKGROUND_VIDEO_PATH = os.path.join(SCRIPT_DIR, "images", "marine_background.mp4")
PROFESSOR_IMAGE_PATH = os.path.join(SCRIPT_DIR, "images", "professor.png")
BOGA_IMAGE_PATH = os.path.join(SCRIPT_DIR, "images", "boga_image.png")
IMAGES_DIR = os.path.join(SCRIPT_DIR, "images")

# Verificação dos caminhos (opcional)
logging.info(f"MODEL_DIR: {MODEL_DIR}")
logging.info(f"BACKGROUND_VIDEO_PATH: {BACKGROUND_VIDEO_PATH}")
logging.info(f"PROFESSOR_IMAGE_PATH: {PROFESSOR_IMAGE_PATH}")
logging.info(f"BOGA_IMAGE_PATH: {BOGA_IMAGE_PATH}")

# 5. Tópicos especificado
TERMS = [
    "Marine Biology", 
    "Biologia Marinha",
    "Aquaculture", 
    "Aquacultura",
    "Seafood Quality", 
    "Qualidade dos Produtos do Mar",
    "Global Changes", 
    "Mudanças Globais",
    "Ecosystem Services", 
    "Serviços dos Ecossistemas",
    "Marine Biotechnology", 
    "Biotecnologia Marinha",
    "Marine Environment", 
    "Ambiente Marinho",
    "Oceanography", 
    "Oceanografia",
    "Climate Change and Oceans", 
    "Mudanças Climáticas e Oceanos",
    "CIIMAR",
    "Cyanobacteria Natural Products", 
    "Produtos Naturais de Cianobactérias",
    "Cyanobacteria", 
    "Cianobactérias",
    "Marine Pollution", 
    "Poluição Marinha",
    "Sustainable Fisheries", 
    "Pesca Sustentável",
    "Marine Conservation", 
    "Conservação Marinha",
    "Marine Ecosystems", 
    "Ecossistemas Marinhos",
    "Biodiversity", 
    "Biodiversidade",
    "Marine Protected Areas", 
    "Áreas Marinhas Protegidas",
    "Coastal Management", 
    "Gestão Costeira",
    "Marine Renewable Energy", 
    "Energias Renováveis Marinhas",
    "Blue Economy", 
    "Economia Azul"
]

# 6. Definir dispositivo para CPU
device = torch.device('cpu')
logging.info("Usando CPU")

# 7. Definir PYTORCH_CUDA_ALLOC_CONF para evitar fragmentação
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

# 8. Função para criar diretório se não existir
def ensure_model_dir_exists(path):
    if not os.path.exists(path):
        os.makedirs(path)
        logging.info(f"Diretório criado: {path}")
    else:
        logging.info(f"Diretório já existe: {path}")

ensure_model_dir_exists(MODEL_DIR)

# 9. Função para carregar o tokenizer
@st.cache_resource
def load_tokenizer(model_dir):
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        logging.info("Tokenizer carregado com sucesso.")
        return tokenizer
    except Exception as e:
        logging.error(f"Erro ao carregar o tokenizer: {e}")
        st.error(f"Ocorreu um erro ao carregar o tokenizer: {e}")
        return None

# 10. Função para carregar o modelo afinado
@st.cache_resource
def load_finetuned_model(model_dir):
    try:
        if not os.path.exists(model_dir):
            logging.error(f"Diretório do modelo afinado não encontrado: {model_dir}")
            st.error(f"Diretório do modelo afinado não encontrado: {model_dir}")
            return None
        logging.info("Carregando o modelo afinado...")
        model = AutoModelForCausalLM.from_pretrained(model_dir)
        model = model.to(device)
        logging.info("Modelo afinado carregado na CPU.")
        return model
    except Exception as e:
        logging.error(f"Erro ao carregar o modelo afinado: {e}")
        st.error(f"O modelo afinado não pôde ser carregado. Detalhes do erro: {e}")
        return None

# 11. Função para realizar o fine-tuning
def perform_finetuning(model_dir, tokenizer):
    try:
        logging.info("Iniciando o fine-tuning do modelo GPT-J-6B...")
        model = AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-j-6B")
        model.to(device)
        
        # Preparar dados
        pubmed_articles = fetch_pubmed_articles(TERMS, retmax=10000)  # Ajustado conforme necessário
        wikipedia_articles = fetch_wikipedia_articles(TERMS, max_articles_per_term=1000)  # Ajustado conforme necessário
        biorxiv_articles = fetch_biorxiv_articles(TERMS, max_articles=10000)  # Ajustado conforme necessário
        
        # Combinar todos os artigos
        all_articles = pubmed_articles + wikipedia_articles + biorxiv_articles
        if not all_articles:
            logging.error("Nenhum artigo encontrado para os termos fornecidos durante o fine-tuning.")
            return False
        
        # Preparar os textos para o fine-tuning
        texts = [f"Title: {article['title']}\nAbstract: {article['abstract']}\n" for article in all_articles]
        
        # Criar o dataset para o fine-tuning
        dataset = datasets.Dataset.from_dict({"text": texts})
        
        # Tokenizar o dataset
        def tokenize_function(examples):
            return tokenizer(examples["text"], truncation=True, max_length=1024)
        
        tokenized_datasets = dataset.map(tokenize_function, batched=True)
        
        # Configurar argumentos de treinamento
        training_args = TrainingArguments(
            output_dir=model_dir,
            overwrite_output_dir=True,
            num_train_epochs=3,
            per_device_train_batch_size=1,
            gradient_accumulation_steps=8,
            learning_rate=1e-5,
            fp16=False,
            save_steps=500,
            save_total_limit=2,
            logging_steps=100,
        )
        
        # Criar Trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_datasets,
            tokenizer=tokenizer,
        )
        
        # Iniciar treinamento
        trainer.train()
        trainer.save_model(model_dir)
        logging.info("Fine-tuning concluído e modelo salvo.")
        return True
    except Exception as e:
        logging.error(f"Erro durante o fine-tuning: {e}")
        return False

# 12. Função para carregar o modelo de embeddings na CPU (opcional)
@st.cache_resource
def load_embedding_model(device):
    try:
        logging.info(f"Carregando o modelo de embeddings 'all-MiniLM-L6-v2' na {device}...")
        embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cpu')
        logging.info("Modelo de embeddings carregado.")
        return embedding_model
    except Exception as e:
        logging.error(f"Erro ao carregar o modelo de embeddings: {e}")
        st.error(f"Ocorreu um erro ao carregar o modelo de embeddings: {e}")
        return None

embedding_model = load_embedding_model(device)

# 13. Funções para buscar artigos

def fetch_pubmed_articles(terms, retmax=10000, years_back=5):
    """
    Busca artigos no PubMed com base nos termos fornecidos.
    """
    all_articles = []
    current_year = datetime.datetime.now().year
    mindate = f"{current_year - years_back}/01/01"
    maxdate = f"{current_year}/12/31"
    
    for term in terms:
        try:
            query = f"{term}[Title/Abstract]"
            handle = Entrez.esearch(
                db="pubmed",
                term=query,
                retmax=retmax,
                mindate=mindate,
                maxdate=maxdate,
                sort="relevance"
            )
            record = Entrez.read(handle)
            id_list = record.get("IdList", [])
            handle.close()
            time.sleep(0.34)  # Respeitar limite de taxa do NCBI
            
            if not id_list:
                logging.info(f"Nenhum artigo encontrado para o termo: {term}")
                continue
            
            # Buscar detalhes dos artigos
            handle = Entrez.efetch(db="pubmed", id=",".join(id_list), retmode="xml")
            records = Entrez.read(handle)
            handle.close()
            time.sleep(0.34)  # Respeitar limite de taxa do NCBI
            
            for record in records.get("PubmedArticle", []):
                article = record["MedlineCitation"]["Article"]
                title = article.get("ArticleTitle", "")
                abstract = article.get("Abstract", {}).get("AbstractText", "")
                if isinstance(abstract, list):
                    abstract_text = " ".join(abstract)
                else:
                    abstract_text = abstract
                all_articles.append({"title": title, "abstract": abstract_text})
            
            logging.info(f"Artigos buscados para o termo: {term}")
        
        except Exception as e:
            logging.error(f"Erro ao buscar artigos para o termo '{term}': {e}")
    
    return all_articles

def fetch_biorxiv_articles(terms, max_articles=100000):
    """
    Busca artigos no bioRxiv usando a API correta, filtrando pelo termo e página.
    """
    biorxiv_articles = []
    base_url = "https://api.biorxiv.org/details/biorxiv/"
    session = requests.Session()
    
    # Configurar retries para lidar com erros temporários
    retries = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retries)
    session.mount('https://', adapter)
    session.mount('http://', adapter)
    
    # Adicionar cabeçalhos para evitar bloqueios (HTTP 403)
    headers = {
        "User-Agent": "LittleFishBOGA/1.0 (mailto:mattoslmp@gmail.com)"
    }
    
    for term in terms:
        try:
            fetched = 0
            page = 0
            while fetched < max_articles:
                url = f"{base_url}{term}/{page}?format=json"
                response = session.get(url, headers=headers, timeout=10)
                
                if response.status_code == 403:
                    logging.error(f"Erro HTTP 403 ao buscar bioRxiv para o termo '{term}' na página {page}")
                    break
                elif response.status_code != 200:
                    logging.error(f"Erro HTTP {response.status_code} ao buscar bioRxiv para o termo '{term}' na página {page}")
                    break
                
                try:
                    data = response.json()
                except json.JSONDecodeError:
                    logging.error(f"Resposta vazia ou inválida do bioRxiv para o termo '{term}' na página {page}")
                    break
                
                articles = data.get("collection", [])
                
                if not articles:
                    break  # Sem mais artigos
                
                for article in articles:
                    if fetched >= max_articles:
                        break
                    title = article.get("preprint_title", "")
                    abstract = article.get("abstract", "")
                    biorxiv_articles.append({"title": title, "abstract": abstract})
                    fetched += 1
                
                page += 1
                time.sleep(0.34)  # Evitar exceder limites de taxa
            
            logging.info(f"Total de {fetched} artigos buscados para o termo: {term}")
        
        except Exception as e:
            logging.error(f"Erro ao buscar artigos do bioRxiv para o termo '{term}': {e}")
    
    return biorxiv_articles

def fetch_wikipedia_articles(terms, max_articles_per_term=1000):
    """
    Busca artigos na Wikipédia com base nos termos fornecidos.
    """
    wikipedia_articles = []
    session = requests.Session()
    search_url = "https://en.wikipedia.org/w/api.php"
    extract_url = "https://en.wikipedia.org/w/api.php"
    
    def fetch_article_extract(page_id):
        try:
            page_params = {
                "action": "query",
                "prop": "extracts",
                "explaintext": True,
                "pageids": page_id,
                "format": "json"
            }
            page_response = session.get(url=extract_url, params=page_params, timeout=10)
            page_response.raise_for_status()
            page_data = page_response.json()
            page = page_data["query"]["pages"].get(str(page_id), {})
            title = page.get("title", "")
            extract = page.get("extract", "")
            abstract = extract[:5000]  # Limitar a 5000 caracteres
            return {"title": title, "abstract": abstract}
        except Exception as e:
            logging.error(f"Erro ao buscar extract do artigo de página ID '{page_id}': {e}")
            return None
    
    for term in terms:
        try:
            params = {
                "action": "query",
                "list": "search",
                "srsearch": term,
                "format": "json",
                "srlimit": max_articles_per_term
            }
            response = session.get(url=search_url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            search_results = data.get("query", {}).get("search", [])
            
            page_ids = [result["pageid"] for result in search_results]
            
            with ThreadPoolExecutor(max_workers=10) as executor:
                future_to_page = {executor.submit(fetch_article_extract, pid): pid for pid in page_ids}
                for future in as_completed(future_to_page):
                    result = future.result()
                    if result:
                        wikipedia_articles.append(result)
            
            logging.info(f"Total de {len(search_results)} artigos buscados para o termo: {term}")
        
        except Exception as e:
            logging.error(f"Erro ao buscar artigos da Wikipédia para o termo '{term}': {e}")
    
    return wikipedia_articles

# 14. Função para processar e indexar artigos (opcional)
def process_and_index_articles(
    articles: List[dict],
    embedding_model: SentenceTransformer = None,
    device: torch.device = torch.device('cpu'),
    batch_size: int = 32,
    chunk_size: int = 500,
    chunk_overlap: int = 50
) -> Tuple[List[str], faiss.Index, SentenceTransformer]:
    """
    Processa e indexa artigos utilizando embeddings e FAISS.
    """
    if embedding_model is None:
        return [], None, None
    
    # Combinar títulos e resumos
    texts = [f"Title: {article.get('title', '')}\nAbstract: {article.get('abstract', '')}" for article in articles]
    logging.info(f"{len(texts)} textos combinados a partir dos artigos.")
    
    # Dividir textos em sentenças e então em chunks
    chunks = []
    for idx, text in enumerate(texts):
        sentences = sent_tokenize(text)
        current_chunk = ""
        for sentence in sentences:
            if len(current_chunk) + len(sentence) + 1 > chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
            else:
                current_chunk += " " + sentence
        if current_chunk:
            chunks.append(current_chunk.strip())
        if (idx + 1) % 1000 == 0:
            logging.info(f"{idx + 1} textos processados para chunks.")
    
    logging.info(f"Total de {len(chunks)} chunks criados.")
    
    # Criar embeddings em lotes para eficiência de memória
    embeddings = []
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        try:
            batch_embeddings = embedding_model.encode(batch, convert_to_numpy=True, show_progress_bar=False)
            embeddings.append(batch_embeddings)
        except Exception as e:
            logging.error(f"Erro ao criar embeddings para o lote {i}-{i+batch_size}: {e}")
    if embeddings:
        embeddings = np.vstack(embeddings)
        logging.info("Embeddings criados.")
    else:
        embeddings = np.array([])
        logging.error("Nenhum embedding foi criado.")
    
    if embeddings.size > 0:
        # Criar o índice FAISS
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings)
        logging.info(f"Índice FAISS criado e {index.ntotal} vetores adicionados.")
    else:
        index = None
        logging.error("Não foi possível criar o índice FAISS devido à falta de embeddings.")
    
    return chunks, index, embedding_model

# 15. Função para gerar respostas
def generate_answer(question, model, tokenizer, lang_code):
    try:
        # Define a instrução de idioma para o modelo
        lang_instructions = {
            "pt": "Responda em Português de forma clara e concisa.",
            "en": "Answer in English clearly and concisely.",
            "es": "Responde en Español de forma clara y concisa."
        }
        language_instruction = lang_instructions.get(lang_code, "Answer in English clearly and concisely.")
        
        # Construir o prompt com base na pergunta e instrução de idioma
        prompt = f"Pergunta: {question}\n{language_instruction}\nResposta:"
        
        # Tokenizar a entrada
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1024)
        input_ids = inputs.input_ids.to(device)
        attention_mask = inputs.attention_mask.to(device)

        # Gerar a resposta usando o modelo afinado
        with torch.no_grad():
            outputs = model.generate(
                input_ids,
                attention_mask=attention_mask,
                max_length=150,  # Limitar a resposta para evitar saídas muito longas
                do_sample=True,
                temperature=0.7,
                pad_token_id=tokenizer.eos_token_id,
                top_p=0.9,
                top_k=50,
                repetition_penalty=1.2,  # Penaliza repetições
                eos_token_id=tokenizer.eos_token_id
            )
        
        # Decodificar a resposta
        answer = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)
        
        # Extrair a parte da resposta após 'Resposta:'
        if "Resposta:" in answer:
            answer = answer.split("Resposta:")[-1].strip()
        elif "Answer:" in answer:
            answer = answer.split("Answer:")[-1].strip()
        elif "Respuesta:" in answer:
            answer = answer.split("Respuesta:")[-1].strip()
        
        # Verificar se a resposta não está vazia
        if not answer:
            return "Desculpe, não consegui encontrar uma resposta para sua pergunta."
        
        return answer
    except Exception as e:
        logging.error(f"Erro ao gerar a resposta: {e}")
        return "Desculpe, houve um erro ao processar sua pergunta."

# 16. Função para falar o texto
def speak(text, lang_code):
    def run_tts():
        lang_speech = {
            "en": "en",
            "pt": "pt",
            "es": "es"
        }
        language = lang_speech.get(lang_code, "en")
        try:
            tts = gTTS(text=text, lang=language)
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                temp_audio = fp.name
                tts.save(temp_audio)
            st.audio(temp_audio)
            os.remove(temp_audio)
        except Exception as e:
            logging.error(f"Erro ao converter texto em fala: {e}")
    
    Thread(target=run_tts).start()

# 17. Função para capturar entrada de voz
def listen(language):
    try:
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            st.write("🎤 Estou ouvindo...")
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)
            st.write("🔍 Processando áudio...")
            text = recognizer.recognize_google(audio, language=language)
            st.write(f"🗣️ Você disse: {text}")
            return text
    except sr.UnknownValueError:
        logging.error("Desculpe, não entendi o que você disse.")
        st.warning("Desculpe, não entendi o que você disse.")
    except sr.RequestError as e:
        logging.error(f"Erro ao se comunicar com o serviço de reconhecimento de fala: {e}")
        st.error(f"Erro ao se comunicar com o serviço de reconhecimento de fala: {e}")
    except sr.WaitTimeoutError:
        logging.error("Tempo de gravação esgotado. Por favor, tente novamente.")
        st.warning("Tempo de gravação esgotado. Por favor, tente novamente.")
    except Exception as e:
        logging.error(f"Ocorreu um erro ao capturar o áudio: {e}")
        st.error(f"Ocorreu um erro ao capturar o áudio: {e}")

# 18. Validação da pergunta
def validate_question(question):
    if not isinstance(question, str) or len(question.strip()) < 5:
        return False
    return True

# 19. Função para determinar o idioma de reconhecimento de voz
def get_recognition_language(lang_code):
    lang_recognition = {
        "en": "en-US",
        "pt": "pt-BR",
        "es": "es-ES"
    }
    return lang_recognition.get(lang_code, "en-US")

# 20. Função para converter imagem em base64
def get_base64_image(image_path):
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except Exception as e:
        logging.error(f"Erro ao carregar a imagem {image_path}: {e}")
        return ""

# 21. Função para adicionar cor de fundo azul
def add_marine_background_color():
    marine_style = """
    <style>
    body {
        background-color: #CCE5FF;  /* Cor azul-marinha */
    }
    .stApp {
        background-color: #CCE5FF;
    }
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background-color: #CCE5FF;
        color: black;
        text-align: center;
        padding: 10px;
    }
    </style>
    """
    st.markdown(marine_style, unsafe_allow_html=True)

# 22. Função para exibir Boga e vídeo lado a lado com descrições em áudio
def display_boga_and_video(selected_language, lang_codes):
    col1, col2 = st.columns([1, 3])

    # Descrições das imagens em diferentes idiomas
    image_descriptions = {
        "boga_image.png": {
            "pt": "Esta é a imagem do Boga, um peixe especial estudado na biologia marinha.",
            "en": "This is an image of Boga, a special fish studied in marine biology.",
            "es": "Esta es una imagen de Boga, un pez especial estudiado en la biología marina."
        },
        "professor.png": {
            "pt": "Esta é a imagem do Professor Marinho, líder do CIIMAR-CNP.",
            "en": "This is an image of Professor Marinho, leader of CIIMAR-CNP.",
            "es": "Esta es una imagen del Profesor Marinho, líder de CIIMAR-CNP."
        }
    }

    with col1:
        # Exibir imagem do Boga com botão para descrição em áudio
        if os.path.exists(BOGA_IMAGE_PATH):
            boga_img_base64 = get_base64_image(BOGA_IMAGE_PATH)
            if boga_img_base64:
                boga_html = f"""
                <div style="text-align: center;">
                    <img src="data:image/png;base64,{boga_img_base64}" alt="Boga" style="max-width: 100%; height: auto;">
                    <p>Boga</p>
                </div>
                """
                st.markdown(boga_html, unsafe_allow_html=True)
                logging.info("Imagem do Boga exibida com sucesso.")
                
                # Botão para ouvir descrição
                description_pt = image_descriptions["boga_image.png"]["pt"]
                description_en = image_descriptions["boga_image.png"]["en"]
                description_es = image_descriptions["boga_image.png"]["es"]
                
                description = ""
                if selected_language == "Português":
                    description = description_pt
                    button_label = "🔊 Ouvir descrição"
                elif selected_language == "English":
                    description = description_en
                    button_label = "🔊 Listen to description"
                elif selected_language == "Español":
                    description = description_es
                    button_label = "🔊 Escuchar descripción"
                else:
                    description = description_en
                    button_label = "🔊 Listen to description"
                
                if st.button(button_label + " - Boga"):
                    speak(description, lang_codes[selected_language])
            else:
                logging.error("Não foi possível converter a imagem do Boga para base64.")
        else:
            logging.error(f"Arquivo de imagem do Boga não encontrado: {BOGA_IMAGE_PATH}")

    with col2:
        # Exibir vídeo de fundo
        if os.path.exists(BACKGROUND_VIDEO_PATH):
            try:
                st.video(BACKGROUND_VIDEO_PATH)
                logging.info("Vídeo de fundo exibido com sucesso.")
            except Exception as e:
                logging.error(f"Erro ao exibir o vídeo de fundo: {e}")
        else:
            logging.error(f"Arquivo de vídeo de fundo não encontrado: {BACKGROUND_VIDEO_PATH}")

def display_professor_image(selected_language, lang_codes):
    # Descrições das imagens em diferentes idiomas
    image_descriptions = {
        "professor.png": {
            "pt": "Esta é a imagem do Professor Marinho, líder do CIIMAR-CNP.",
            "en": "This is an image of Professor Marinho, leader of CIIMAR-CNP.",
            "es": "Esta es una imagen del Profesor Marinho, líder de CIIMAR-CNP."
        }
    }

    # Exibir imagem do Professor com botão para descrição em áudio
    if os.path.exists(PROFESSOR_IMAGE_PATH):
        professor_img_base64 = get_base64_image(PROFESSOR_IMAGE_PATH)
        if professor_img_base64:
            professor_html = f"""
            <div style="text-align: center;">
                <img src="data:image/png;base64,{professor_img_base64}" alt="Professor Marinho" style="max-width: 100%; height: auto;">
                <p>Professor Marinho</p>
            </div>
            """
            st.markdown(professor_html, unsafe_allow_html=True)
            logging.info("Imagem do Professor exibida com sucesso.")
            
            # Botão para ouvir descrição
            description_pt = image_descriptions["professor.png"]["pt"]
            description_en = image_descriptions["professor.png"]["en"]
            description_es = image_descriptions["professor.png"]["es"]
            
            description = ""
            if selected_language == "Português":
                description = description_pt
                button_label = "🔊 Ouvir descrição"
            elif selected_language == "English":
                description = description_en
                button_label = "🔊 Listen to description"
            elif selected_language == "Español":
                description = description_es
                button_label = "🔊 Escuchar descripción"
            else:
                description = description_en
                button_label = "🔊 Listen to description"
            
            if st.button(button_label + " - Professor"):
                speak(description, lang_codes[selected_language])
        else:
            logging.error("Não foi possível converter a imagem do Professor para base64.")
    else:
        logging.error(f"Arquivo de imagem do Professor não encontrado: {PROFESSOR_IMAGE_PATH}")

# 23. Função para adicionar o rodapé com assinatura e imagem do professor
def add_footer():
    professor_img_base64 = get_base64_image(PROFESSOR_IMAGE_PATH)
    if professor_img_base64:
        footer_html = f"""
        <div class="footer">
        <div style="display: flex; justify-content: center; align-items: center;">
            <p style='color: black; margin: 0; padding-right: 10px;'>
                Authors: Leandro de Mattos Pereira<sup>1</sup>, Vitor Vasconcellos<sup>2</sup> and Pedro Leão<sup>1</sup> 
                <br>CIIMAR
                <br>Cyanobacterial Natural Products Laboratory<sup>1</sup>.
                <br>Blue Biotechnology, Environment and Health<sup>2</sup>
                <br>Authors and CIIMAR (Interdisciplinary Centre of Marine and Environmental Research) @2024 - All rights reserved.
            </p>
        <img src="data:image/png;base64,{professor_img_base64}" alt="Boga Fish - Professor Marinho" width="100">
            </div>
        </div>
        """   
        st.markdown(footer_html, unsafe_allow_html=True)
    else:
        logging.error("Imagem do professor não pôde ser carregada no rodapé.")

# 24. Função principal com exibição de vídeo, imagens, rodapé e processamento no backend
def main():
    # Adicionar fundo azul
    add_marine_background_color()

    # Sidebar de configurações
    st.sidebar.title("Configurações")
    show_background = st.sidebar.checkbox("Mostrar vídeo de fundo temático", value=False, key="show_background_checkbox")  # Desabilitado por padrão
    selected_language = st.sidebar.selectbox("Selecione o idioma:", ["Português", "English", "Español"], key="language_selectbox")
    lang_codes = {"Português": "pt", "English": "en", "Español": "es"}
    lang_code = lang_codes[selected_language]

    # Opção para exibir vídeo de fundo adicional se necessário
    if show_background and os.path.exists(BACKGROUND_VIDEO_PATH):
        st.sidebar.video(BACKGROUND_VIDEO_PATH)
    elif show_background and not os.path.exists(BACKGROUND_VIDEO_PATH):
        st.sidebar.error("Arquivo de vídeo de fundo não encontrado.")

    # Exibir imagens com descrições em áudio
    col_images = st.columns(2)
    with col_images[0]:
        display_boga_and_video(selected_language, lang_codes)
    with col_images[1]:
        display_professor_image(selected_language, lang_codes)

    st.write("### Perguntas sobre biologia marinha:")
    input_method = st.radio("Escolha o método de entrada:", ("Texto", "Voz"), key="input_method_radio")

    # Carregar ou configurar o modelo
    if 'model_loaded' not in st.session_state:
        model = None
        tokenizer = None
    else:
        model = st.session_state.model
        tokenizer = st.session_state.tokenizer

    if input_method == "Texto":
        question = st.text_input("Digite sua pergunta aqui:", max_chars=500, key="question_text_input")
        if st.button("Enviar", key="send_button"):
            if question and validate_question(question):
                if 'model_loaded' not in st.session_state:
                    with st.spinner("O Boga fish está estudando e aprendendo - por favor, espere mais um pouco."):
                        model, tokenizer = setup_model()
                        if model and tokenizer:
                            st.session_state.model = model
                            st.session_state.tokenizer = tokenizer
                            st.session_state.model_loaded = True
                        else:
                            st.error("Falha no carregamento do modelo.")
                            st.stop()
                else:
                    model = st.session_state.model
                    tokenizer = st.session_state.tokenizer

                # Gerar a resposta
                answer = generate_answer(question, model, tokenizer, lang_code)
                st.write("#### Resposta:")
                st.write(answer)
                if answer:
                    if selected_language == "Português":
                        button_label = "🔊 Ouvir Resposta"
                    elif selected_language == "English":
                        button_label = "🔊 Listen to Answer"
                    elif selected_language == "Español":
                        button_label = "🔊 Escuchar Respuesta"
                    else:
                        button_label = "🔊 Listen to Answer"
                    # Botão unificado para ouvir a resposta
                    if st.button(button_label, on_click=lambda: speak(answer, lang_code), key="speak_button"):
                        pass  # A ação já é realizada pelo on_click
            else:
                st.warning("Por favor, insira uma pergunta válida.")
    else:
        if st.button("🎤 Gravar Pergunta", key="record_button"):
            question = listen(get_recognition_language(lang_code))
            if question:
                if validate_question(question):
                    if 'model_loaded' not in st.session_state:
                        with st.spinner("O Boga fish está estudando e aprendendo - por favor, espere mais um pouco."):
                            model, tokenizer = setup_model()
                            if model and tokenizer:
                                st.session_state.model = model
                                st.session_state.tokenizer = tokenizer
                                st.session_state.model_loaded = True
                            else:
                                st.error("Falha no carregamento do modelo.")
                                st.stop()
                    else:
                        model = st.session_state.model
                        tokenizer = st.session_state.tokenizer

                    # Gerar a resposta
                    answer = generate_answer(question, model, tokenizer, lang_code)
                    st.write("#### Resposta:")
                    st.write(answer)
                    if answer:
                        if selected_language == "Português":
                            button_label = "🔊 Ouvir Resposta"
                        elif selected_language == "English":
                            button_label = "🔊 Listen to Answer"
                        elif selected_language == "Español":
                            button_label = "🔊 Escuchar Respuesta"
                        else:
                            button_label = "🔊 Listen to Answer"
                        # Botão unificado para ouvir a resposta
                        if st.button(button_label, on_click=lambda: speak(answer, lang_code), key="speak_button"):
                            pass  # A ação já é realizada pelo on_click
                else:
                    st.warning("Por favor, insira uma pergunta válida.")
            else:
                st.warning("Não foi possível obter sua pergunta.")

    # Adicionar rodapé com assinatura e imagem do professor
    add_footer()

# 25. Função para carregar o modelo ou realizar fine-tuning se necessário
def setup_model():
    if not os.listdir(MODEL_DIR):  # Verifica se o diretório está vazio
        logging.info("Modelo afinado não encontrado. Iniciando o fine-tuning.")
        tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-j-6B")
        success = perform_finetuning(MODEL_DIR, tokenizer)
        if success:
            # Recarregar o tokenizer e o modelo afinado após o fine-tuning
            tokenizer = load_tokenizer(MODEL_DIR)
            model = load_finetuned_model(MODEL_DIR)
            return model, tokenizer
        else:
            logging.error("Falha no fine-tuning do modelo.")
            return None, None
    else:
        logging.info("Modelo afinado encontrado. Carregando o modelo...")
        tokenizer = load_tokenizer(MODEL_DIR)
        model = load_finetuned_model(MODEL_DIR)
        return model, tokenizer

if __name__ == "__main__":
    # Suprimir warnings específicos
    warnings.filterwarnings("ignore", category=FutureWarning, module="transformers.tokenization_utils_base")
    warnings.filterwarnings("ignore", category=UserWarning, module="torch._utils")
    main()

